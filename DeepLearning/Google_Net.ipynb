{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_module(input,No_of_filters,filtersizeX,filtersizeY,stride,chanDim,padding=\"same\"):\n",
    "  input = Conv2D(No_of_filters,(filtersizeX,filtersizeY),strides=stride,padding=padding)(input)\n",
    "  input = BatchNormalization(axis=chanDim)(input)\n",
    "  input = Activation(\"relu\")(input)\n",
    "  return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(input,numK1x1,numK3x3,numk5x5,numPoolProj,chanDim):\n",
    "                                 #Step 1\n",
    "  conv_1x1 = conv_module(input, numK1x1, 1, 1,(1, 1), chanDim) \n",
    "                                 #Step 2\n",
    "  conv_3x3 = conv_module(input, numK3x3, 3, 3,(1, 1), chanDim)\n",
    "  conv_5x5 = conv_module(input, numk5x5, 5, 5,(1, 1), chanDim)\n",
    "                                 #Step 3\n",
    "  pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "  pool_proj = Conv2D(numPoolProj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
    "                                 #Step 4\n",
    "  input = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=chanDim)\n",
    "  return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_module(input,No_of_filters,chanDim):\n",
    "  conv_3x3=conv_module(input,No_of_filters,3,3,(2,2),chanDim,padding=\"valid\")\n",
    "  pool = MaxPooling2D((3,3),strides=(2,2))(input)\n",
    "  input = concatenate([conv_3x3,pool],axis=chanDim)\n",
    "  return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MiniGoogleNet(width,height,depth,classes):\n",
    "  inputShape=(height,width,depth)\n",
    "  chanDim=-1\n",
    "\n",
    "  # (Step 1) Define the model input\n",
    "  inputs = Input(shape=inputShape)\n",
    "\n",
    "  # First CONV module\n",
    "  x = conv_module(inputs, 96, 3, 3, (1, 1),chanDim)\n",
    "\n",
    "  # (Step 2) Two Inception modules followed by a downsample module\n",
    "  x = inception_module(x, 32, 32,32,32,chanDim)\n",
    "  x = inception_module(x, 32, 48, 48,32,chanDim)\n",
    "  x = downsample_module(x, 80, chanDim)\n",
    "  \n",
    "  # (Step 3) Five Inception modules followed by a downsample module\n",
    "  x = inception_module(x, 112, 48, 32, 48,chanDim)\n",
    "  x = inception_module(x, 96, 64, 32,32,chanDim)\n",
    "  x = inception_module(x, 80, 80, 32,32,chanDim)\n",
    "  x = inception_module(x, 48, 96, 32,32,chanDim)\n",
    "  x = inception_module(x, 112, 48, 32, 48,chanDim)\n",
    "  x = downsample_module(x, 96, chanDim)\n",
    "\n",
    "  # (Step 4) Two Inception modules followed\n",
    "  x = inception_module(x, 176, 160,96,96, chanDim)\n",
    "  x = inception_module(x, 176, 160, 96,96,chanDim)\n",
    "  \n",
    "  # Global POOL and dropout\n",
    "  x = AveragePooling2D((7, 7))(x)\n",
    "  x = Dropout(0.5)(x)\n",
    "\n",
    "  # (Step 5) Softmax classifier\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(classes)(x)\n",
    "  x = Activation(\"softmax\")(x)\n",
    "\n",
    "  # Create the model\n",
    "  model = Model(inputs, x, name=\"googlenet\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "INIT_LR = 5e-3\n",
    "def poly_decay(epoch):\n",
    "  maxEpochs = NUM_EPOCHS\n",
    "  baseLR = INIT_LR\n",
    "  power = 1.0\n",
    "  alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    "  return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\")\n",
    "testX = testX.astype(\"float\")\n",
    "                                # Step 1\n",
    "mean = np.mean(trainX, axis=0)\n",
    "trainX -= mean\n",
    "testX -= mean\n",
    "                                # Step 2\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "                                # Step 3\n",
    "aug = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1, horizontal_flip=True,fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[LearningRateScheduler(poly_decay)]\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model = GoogleNet(width=32, height=32, depth=3, classes=10)\n",
    "                                    # Step 1\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "                                    # Step 2\n",
    "model.fit(aug.flow(trainX, trainY, batch_size=64),validation_data=(testX, testY), steps_per_epoch=len(trainX) // 64,epochs=NUM_EPOCHS, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
